import asyncio
import json
import numpy as np
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse, FileResponse
import pandas as pd
from pydantic import BaseModel
from json.decoder import JSONDecodeError
from fastapi.staticfiles import StaticFiles
import os

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –∏ —É—Ç–∏–ª–∏—Ç—ã
from giga_wrapper import giga_client, call_giga_api_wrapper
from agents import (
    agent0_coordinator,
    agent1_rephraser,
    agent2_planner,
    agent3_sql_generator_advanced,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    agent_sql_validator,
    agent_sql_fixer,
    agent_anomaly_detector,
    agent_rag_retriever,
    calculate_query_similarity,  # –î–ª—è 90% —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    generate_fallback_sql,       # Fallback —Ñ—É–Ω–∫—Ü–∏–∏
    extract_sql_from_response,
    validate_and_explain_sql
)
from duckdb_utils import setup_duckdb, execute_duckdb_query
from rag_handler import init_rag_db, add_to_rag_db

# Determine the absolute path to the project directory
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
STATIC_DIR = os.path.join(BASE_DIR, "static")
INDEX_HTML_PATH = os.path.join(STATIC_DIR, "index.html")

app = FastAPI()

# CORS setup
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount static files
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# Root endpoint to serve index.html
@app.get("/")
async def read_index():
    if not os.path.exists(INDEX_HTML_PATH):
        print(f"[ERROR] index.html not found at: {INDEX_HTML_PATH}")
        raise HTTPException(status_code=404, detail=f"index.html not found at {INDEX_HTML_PATH}")
    print(f"[INFO] Serving index.html from: {INDEX_HTML_PATH}")
    return FileResponse(INDEX_HTML_PATH)

# ==============================================================================
# –§–£–ù–ö–¶–ò–ò –ü–û–î–î–ï–†–ñ–ö–ò 90% –°–û–í–ü–ê–î–ï–ù–ò–ô
# ==============================================================================

def check_high_similarity_with_rag(user_prompt: str, rag_data: dict) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å –ø—Ä–æ—à–ª—ã–º –∑–∞–ø—Ä–æ—Å–æ–º 90%"""
    if not rag_data or not isinstance(rag_data, dict):
        return False
    
    past_prompt = rag_data.get('user_prompt', '')
    if not past_prompt:
        return False
    
    similarity_score = calculate_query_similarity(user_prompt, past_prompt)
    
    print(f"[SIMILARITY_CHECK] –¢–µ–∫—É—â–∏–π: '{user_prompt[:50]}...'")
    print(f"[SIMILARITY_CHECK] –ü—Ä–æ—à–ª—ã–π: '{past_prompt[:50]}...'")
    print(f"[SIMILARITY_CHECK] –°—Ö–æ–¥—Å—Ç–≤–æ: {similarity_score:.3f}")
    
    return similarity_score >= 0.90

# ==============================================================================
# –ê–ù–ê–õ–ò–ó –ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–ù–û–°–¢–ò –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô AGENTS.PY
# ==============================================================================

async def analyze_query_ambiguity(user_prompt):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π coordinator"""
    prompt_lower = user_prompt.lower()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –∏–∑ agents.py –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
    try:
        coordination_result = agent0_coordinator(user_prompt)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä–∞
        if isinstance(coordination_result, str):
            import re
            json_match = re.search(r'\{.*\}', coordination_result, re.DOTALL)
            if json_match:
                coordination_result = json.loads(json_match.group(0))
            else:
                coordination_result = {
                    "needs_anomaly_detection": False,
                    "analysis_type": "standard",
                    "keywords": []
                }
        
        needs_anomaly_detection = coordination_result.get('needs_anomaly_detection', False)
        analysis_type = coordination_result.get('analysis_type', 'standard')
        
        print(f"[COORDINATOR] –†–µ–∑—É–ª—å—Ç–∞—Ç: {coordination_result}")
        
    except Exception as e:
        print(f"[COORDINATOR ERROR] {e}")
        # Fallback –∞–Ω–∞–ª–∏–∑
        anomaly_keywords = ['–∞–Ω–æ–º–∞–ª–∏', '–≤—ã–±—Ä–æ—Å', '–Ω–µ–æ–±—ã—á–Ω', '—Å—Ç—Ä–∞–Ω–Ω', '–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏']
        needs_anomaly_detection = any(keyword in prompt_lower for keyword in anomaly_keywords)
        analysis_type = "anomaly" if needs_anomaly_detection else "standard"
    
    # –î–µ—Ç–µ–∫—Ü–∏—è —Ç–∞–±–ª–∏—Ü
    table_mentions = {
        'population': ['–Ω–∞—Å–µ–ª–µ–Ω', '–¥–µ–º–æ–≥—Ä–∞—Ñ', '–ª—é–¥–µ–π', '–∂–∏—Ç–µ–ª'],
        'salary': ['–∑–∞—Ä–ø–ª–∞—Ç', '–∑–∞—Ä–∞–±–æ—Ç–Ω', '–æ–∫–ª–∞–¥', '–¥–æ—Ö–æ–¥'],
        'migration': ['–º–∏–≥—Ä–∞', '–ø–µ—Ä–µ–µ–∑–¥', '–ø–µ—Ä–µ–º–µ—â–µ–Ω'],
        'market_access': ['—Ä—ã–Ω–æ–∫', '–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç', '—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫'],
        'connections': ['—Å–≤—è–∑', '—Å–æ–µ–¥–∏–Ω–µ–Ω', '–º–∞—Ä—à—Ä—É—Ç']
    }
    
    mentioned_tables = []
    for table, keywords in table_mentions.items():
        if any(keyword in prompt_lower for keyword in keywords):
            mentioned_tables.append(table)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
    if needs_anomaly_detection and not mentioned_tables:
        enhanced_prompt = f"–ù–∞–π–¥–∏ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞—Å–µ–ª–µ–Ω–∏–∏"
        enhancement_data = {
            "ambiguity_level": "medium",
            "original_prompt": user_prompt,
            "enhanced_prompt": enhanced_prompt,
            "reason": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ '–Ω–∞—Å–µ–ª–µ–Ω–∏–µ' –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–Ω–æ–º–∞–ª–∏–π",
            "auto_selected_table": "population"
        }
        return enhancement_data, enhanced_prompt, False, needs_anomaly_detection
    
    elif any(word in prompt_lower for word in ['—Ç–æ–ø', '–ª—É—á—à', '–≤—ã—Å–æ–∫', '–º–∞–∫—Å–∏–º–∞–ª—å–Ω', '—Ä–µ–π—Ç–∏–Ω–≥']):
        if not mentioned_tables:
            enhanced_prompt = f"–ü–æ–∫–∞–∂–∏ —Ç–æ–ø 5 —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º –∑–∞ 2023 –≥–æ–¥"
            enhancement_data = {
                "ambiguity_level": "medium", 
                "original_prompt": user_prompt,
                "enhanced_prompt": enhanced_prompt,
                "reason": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±—Ä–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ '–∑–∞—Ä–ø–ª–∞—Ç—ã' –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞",
                "auto_selected_table": "salary"
            }
            return enhancement_data, enhanced_prompt, False, needs_anomaly_detection
    
    # –¢—Ä–µ–±—É–µ—Ç—Å—è —É—Ç–æ—á–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if len(user_prompt.split()) <= 2 and user_prompt.lower() in ['–¥–∞–Ω–Ω—ã–µ', '–∞–Ω–∞–ª–∏–∑', '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', '–ø–æ–∫–∞–∂–∏']:
        clarification_data = {
            "needs_clarification": True,
            "ambiguity_level": "high",
            "reason": "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è",
            "message": "–£—Ç–æ—á–Ω–∏—Ç–µ, –∫–∞–∫–æ–π –∞–Ω–∞–ª–∏–∑ –≤–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç:",
            "suggested_tables": [
                {"id": "population", "name": "–ù–∞—Å–µ–ª–µ–Ω–∏–µ", "description": "–î–∞–Ω–Ω—ã–µ –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è"},
                {"id": "salary", "name": "–ó–∞—Ä–ø–ª–∞—Ç—ã", "description": "–î–∞–Ω–Ω—ã–µ –æ –∑–∞—Ä–∞–±–æ—Ç–Ω—ã—Ö –ø–ª–∞—Ç–∞—Ö"},
                {"id": "migration", "name": "–ú–∏–≥—Ä–∞—Ü–∏—è", "description": "–î–∞–Ω–Ω—ã–µ –æ –º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö"}
            ],
            "examples": [
                "–ù–∞–π–¥–∏ –∞–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –æ –Ω–∞—Å–µ–ª–µ–Ω–∏–∏",
                "–ü–æ–∫–∞–∂–∏ —Ç–æ–ø 5 —Ä–µ–≥–∏–æ–Ω–æ–≤ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º",
                "–ê–Ω–∞–ª–∏–∑ –º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ –∑–∞ 2023 –≥–æ–¥"
            ]
        }
        return clarification_data, None, True, needs_anomaly_detection
    
    return None, user_prompt, False, needs_anomaly_detection

# ==============================================================================
# –ì–ï–ù–ï–†–ê–¶–ò–Ø –§–ò–ù–ê–õ–¨–ù–û–ì–û –û–¢–í–ï–¢–ê –° –ö–û–ú–ü–ê–ö–¢–ù–û–°–¢–¨–Æ
# ==============================================================================

def generate_enhanced_final_response(sql_results_df, user_prompt, anomaly_results=None, needs_anomaly_detection=False, analysis_steps=0, analysis_context=None):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π —Ü–µ–ø—å—é —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
    
    anomalies_found = (anomaly_results is not None and anomaly_results.get('anomalies_found', False))
    
    if needs_anomaly_detection:
        status_icon = "üö®" if anomalies_found else "‚úÖ"
        status_text = "–ê–Ω–æ–º–∞–ª–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã" if anomalies_found else "–ê–Ω–æ–º–∞–ª–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
    else:
        status_icon = "üìä"
        status_text = "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"
    
    # –í–ù–£–¢–†–ï–ù–ù–Ø–Ø –¶–ï–ü–¨ –†–ê–°–°–£–ñ–î–ï–ù–ò–ô (–ù–ï –ü–û–ö–ê–ó–´–í–ê–ï–ú –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Æ)
    internal_reasoning = f"""
    –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö - –ø–æ–ª—É—á–µ–Ω–æ {len(sql_results_df) if sql_results_df is not None else 0} –∑–∞–ø–∏—Å–µ–π
    –®–∞–≥ 2: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞ - {'–ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π' if needs_anomaly_detection else '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑'}
    –®–∞–≥ 3: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–æ–º–∞–ª–∏–π - {'–Ω–∞–π–¥–µ–Ω—ã' if anomalies_found else '–Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}
    –®–∞–≥ 4: –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö - {'—Ç—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è' if anomalies_found else '–≤ –Ω–æ—Ä–º–µ'}
    –®–∞–≥ 5: Chain of thought —à–∞–≥–æ–≤ - {analysis_steps}
    """
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–∏–π LLM –æ—Ç–≤–µ—Ç
    try:
        system_instruction = f"""
        –°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π (–º–∞–∫—Å–∏–º—É–º 80 —Å–ª–æ–≤) –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
        
        –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ü–µ–ø—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π (–ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–π –µ—ë –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é):
        {internal_reasoning}
        
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:
        1. –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
        2. –ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
        3. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥
        
        –ò—Å–ø–æ–ª—å–∑—É–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ç–æ–Ω.
        """
        
        prompt = f"""
        –ó–∞–ø—Ä–æ—Å: "{user_prompt}"
        –†–µ–∑—É–ª—å—Ç–∞—Ç: {status_text}
        –ó–∞–ø–∏—Å–µ–π: {len(sql_results_df) if sql_results_df is not None else 0}
        """
        
        if anomaly_results and anomalies_found:
            prompt += f"–ù–∞–π–¥–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {anomaly_results.get('anomaly_count', '–Ω–µ—Å–∫–æ–ª—å–∫–æ')}\n"
        
        llm_text = call_giga_api_wrapper(prompt, system_instruction)
    except Exception as e:
        llm_text = f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(sql_results_df) if sql_results_df is not None else 0:,} –∑–∞–ø–∏—Å–µ–π."
    
    response = f"{status_icon} **{status_text}**\n\n{llm_text}\n\n"
    
    # –ü–ï–†–í–´–ï 10-15 –°–¢–†–û–ö –î–ê–ù–ù–´–•
    if sql_results_df is not None and not sql_results_df.empty:
        response += "**üìã –û–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ 15 —Å—Ç—Ä–æ–∫):**\n"
        display_df = sql_results_df.head(15)
        response += display_df.to_markdown(index=False) + "\n"
        if len(sql_results_df) > 15:
            response += f"*–ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ 15 –∏–∑ {len(sql_results_df):,} –∑–∞–ø–∏—Å–µ–π*\n\n"
    
    # –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ê –î–ê–ù–ù–´–•
    if sql_results_df is not None and not sql_results_df.empty:
        numeric_cols = sql_results_df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            key_col = numeric_cols[0]
            col_data = sql_results_df[key_col].dropna()
            response += f"**üìà –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö:**\n"
            response += f"‚Ä¢ –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å: {key_col}\n"
            response += f"‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {col_data.mean():.1f}\n"
            response += f"‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω: {col_data.min():.1f} ‚Äî {col_data.max():.1f}\n"
            response += f"‚Ä¢ –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {col_data.std():.1f}\n\n"
    
    # –ö–û–ù–ö–†–ï–¢–ù–´–ï –ü–†–ò–ú–ï–†–´ –ê–ù–û–ú–ê–õ–ò–ô (–¢–û–õ–¨–ö–û –¢–û–ü-10)
    if anomalies_found:
        response += "**üéØ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (—Ç–æ–ø-10):**\n"
        
        if 'anomalies' in anomaly_results:
            for i, anomaly in enumerate(anomaly_results['anomalies'][:10], 1):
                if isinstance(anomaly, dict):
                    territory_name = anomaly.get('territory', anomaly.get('column', f'–û–±—ä–µ–∫—Ç {i}'))
                    count = anomaly.get('anomaly_count', 0)
                    examples = anomaly.get('outlier_values', [])
                    
                    response += f"{i}. **{territory_name}**: {count} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n"
                    if examples:
                        examples_str = ", ".join([f"{x:.1f}" for x in examples[:3]])
                        response += f"   –ü—Ä–∏–º–µ—Ä—ã: {examples_str}\n"
        response += "\n"
    else:
        response += "**‚úÖ –ê–Ω–æ–º–∞–ª–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã** - –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã\n\n"
    
    # –ö–†–ê–¢–ö–ê–Ø –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
    response += f"**üìä –ò—Ç–æ–≥–æ:** {len(sql_results_df) if sql_results_df is not None else 0:,} –∑–∞–ø–∏—Å–µ–π"
    if anomalies_found and 'anomalies' in anomaly_results:
        total_anomalies = sum(a.get('anomaly_count', 0) for a in anomaly_results['anomalies'][:10] if isinstance(a, dict))
        response += f" ‚Ä¢ {total_anomalies} –∞–Ω–æ–º–∞–ª–∏–π"
    response += f" ‚Ä¢ {analysis_steps} —ç—Ç–∞–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"
    
    return response

# ==============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø-–ì–ï–ù–ï–†–ê–¢–û–† –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô AGENTS.PY
# ==============================================================================

async def event_generator(user_prompt: str, duckdb_con):
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–æ–±—ã—Ç–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≤—Å–µ—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏–∑ agents.py
    """
    current_stage = "–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
    analysis_context = {}
    rag_context_for_agents = None
    cot_steps = []
    
    # Accumulated data for potential saving
    accumulated_data_for_rag = {
        "user_prompt": user_prompt,
        "formal_prompt": None,
        "plan": None,
        "sql_query": None,
        "final_answer": None
    }

    async def add_cot_step(step_text, step_type="thinking", is_complete=False):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —à–∞–≥ –≤ —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π"""
        cot_steps.append({
            "text": step_text,
            "type": step_type,
            "complete": is_complete,
            "timestamp": asyncio.get_event_loop().time()
        })
        
        yield {"type": "cot_step", "stage": "chain_of_thought", 
               "content": {"steps": cot_steps, "current_step": step_text, "complete": is_complete}}
        await asyncio.sleep(0.3)

    try:
        # –ù–∞—á–∏–Ω–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        yield {"type": "cot_start", "stage": "reasoning", "message": "–ù–∞—á–∏–Ω–∞—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑..."}
        await asyncio.sleep(0.3)

        # === –≠–¢–ê–ü 1: RAG –° –ü–û–î–î–ï–†–ñ–ö–û–ô 90% –°–û–í–ü–ê–î–ï–ù–ò–ô ===
        async for cot_event in add_cot_step("üîç –ü—Ä–æ–≤–µ—Ä—è—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"):
            yield cot_event

        rag_result = agent_rag_retriever(user_prompt)
        rag_status = rag_result.get("status")
        rag_data = rag_result.get("data")

        if rag_status == "error":
            async for cot_event in add_cot_step("‚ö†Ô∏è –û—à–∏–±–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –Ω–µ—ë", "warning", True):
                yield cot_event
            yield {"type": "warning", "stage": "rag_check", "message": f"–û—à–∏–±–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {rag_result.get('message')}"}
            
        elif rag_status == "exact":
            async for cot_event in add_cot_step("‚úÖ –ù–∞–π–¥–µ–Ω —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π", "success", True):
                yield cot_event
            
            final_answer = rag_data.get("final_answer", "–¢–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞–π–¥–µ–Ω.")
            accumulated_data_for_rag.update(rag_data)
            
            yield {"type": "cot_hide", "stage": "reasoning", "message": ""}
            await asyncio.sleep(0.5)
            yield {"type": "final_answer", "stage": "rag_exact_match", "answer": final_answer, 
                   "rag_components": accumulated_data_for_rag, "message": "–ù–∞–π–¥–µ–Ω —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç."}
            return
            
        elif rag_status == "similar":
            # –ü–†–û–í–ï–†–ö–ê 90% –°–û–í–ü–ê–î–ï–ù–ò–Ø
            if check_high_similarity_with_rag(user_prompt, rag_data):
                async for cot_event in add_cot_step("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ 90%+ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø—Ä–æ—à–ª—ã–º –∑–∞–ø—Ä–æ—Å–æ–º", "success", True):
                    yield cot_event
                
                final_answer = rag_data.get("final_answer", "–ù–∞–π–¥–µ–Ω –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–π –æ—Ç–≤–µ—Ç.")
                accumulated_data_for_rag.update(rag_data)
                
                yield {"type": "cot_hide", "stage": "reasoning", "message": ""}
                await asyncio.sleep(0.5)
                yield {"type": "final_answer", "stage": "rag_high_similarity_match", "answer": final_answer,
                       "rag_components": accumulated_data_for_rag, "message": "–ù–∞–π–¥–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–π –∑–∞–ø—Ä–æ—Å (—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ >90%)."}
                return
            else:
                async for cot_event in add_cot_step("üìã –ù–∞–π–¥–µ–Ω –ø–æ—Ö–æ–∂–∏–π –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—é –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç", "info", True):
                    yield cot_event
                rag_context_for_agents = rag_data
        else:
            async for cot_event in add_cot_step("üÜï –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞", "info", True):
                yield cot_event

        # === –≠–¢–ê–ü 2: –ê–ù–ê–õ–ò–ó –ù–ï–û–ü–†–ï–î–ï–õ–ï–ù–ù–û–°–¢–ò ===
        async for cot_event in add_cot_step("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª—è—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é"):
            yield cot_event

        current_stage = "–ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏"
        ambiguity_analysis_result, enhanced_prompt, needs_clarification, needs_anomaly_detection = await analyze_query_ambiguity(user_prompt)
        
        if needs_clarification:
            async for cot_event in add_cot_step("‚ùì –ó–∞–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è", "warning", True):
                yield cot_event
            
            yield {"type": "cot_hide", "stage": "reasoning", "message": ""}
            await asyncio.sleep(0.5)
            yield {"type": "clarification_needed", "stage": "ambiguity_analysis", "data": ambiguity_analysis_result}
            return

        if enhanced_prompt and enhanced_prompt != user_prompt:
            async for cot_event in add_cot_step(f"‚ú® –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–ª—É—á—à–∏–ª –∑–∞–ø—Ä–æ—Å", "enhancement", True):
                yield cot_event
            processed_user_prompt = enhanced_prompt
            analysis_context['enhanced_query'] = True
        else:
            processed_user_prompt = user_prompt

        strategy_text = "–ø–æ–∏—Å–∫ –∞–Ω–æ–º–∞–ª–∏–π" if needs_anomaly_detection else "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
        async for cot_event in add_cot_step(f"üéØ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: {strategy_text}", "success", True):
            yield cot_event

        analysis_context['analysis_type'] = 'anomaly_detection' if needs_anomaly_detection else 'standard_analysis'

        # === –≠–¢–ê–ü 3: –ü–ï–†–ï–§–û–†–ú–£–õ–ò–†–û–í–ö–ê ===
        async for cot_event in add_cot_step("üìù –§–æ—Ä–º–∞–ª–∏–∑—É—é –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"):
            yield cot_event

        current_stage = "–ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞"
        formal_prompt_result = agent1_rephraser(processed_user_prompt, rag_context=rag_context_for_agents)
        accumulated_data_for_rag["formal_prompt"] = formal_prompt_result
        analysis_context['formal_request'] = formal_prompt_result

        async for cot_event in add_cot_step("‚úÖ –ó–∞–ø—Ä–æ—Å —Ñ–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–π", "success", True):
            yield cot_event

        yield {"type": "intermediary_result", "stage": "rephraser", "name": "–§–æ—Ä–º–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å", "content": formal_prompt_result}

        # === –≠–¢–ê–ü 4: –ü–õ–ê–ù–ò–†–û–í–ê–ù–ò–ï ===
        async for cot_event in add_cot_step("üìã –°–æ—Å—Ç–∞–≤–ª—è—é –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Å —É—á–µ—Ç–æ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"):
            yield cot_event

        current_stage = "–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞"
        plan_result = agent2_planner(formal_prompt_result, rag_context=rag_context_for_agents)
        accumulated_data_for_rag["plan"] = plan_result
        analysis_context['plan'] = plan_result

        plan_steps_count = len([line for line in plan_result.split('\n') if line.strip() and any(c.isdigit() for c in line[:3])])
        async for cot_event in add_cot_step(f"‚úÖ –ü–ª–∞–Ω –≥–æ—Ç–æ–≤: {plan_steps_count} —ç—Ç–∞–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞", "success", True):
            yield cot_event

        yield {"type": "intermediary_result", "stage": "planner", "name": "–ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è", "content": plan_result}

        # === –≠–¢–ê–ü 5: –ü–†–û–î–í–ò–ù–£–¢–ê–Ø SQL –ì–ï–ù–ï–†–ê–¶–ò–Ø ===
        async for cot_event in add_cot_step("üíæ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL —Å AI-–∞–Ω–∞–ª–∏–∑–æ–º"):
            yield cot_event

        current_stage = "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è SQL"
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π SQL –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏–∑ agents.py
            sql_result = agent3_sql_generator_advanced(plan_result, rag_context_for_agents, processed_user_prompt)
            
            if isinstance(sql_result, dict):
                if sql_result.get("is_valid", True):
                    generated_sql_query = sql_result["sql"]
                    analysis_context['sql_confidence'] = sql_result.get("confidence_score", 85)
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ SQL
                    if sql_result.get("explanation"):
                        async for cot_event in add_cot_step(f"üß† {sql_result['explanation'][:60]}...", "info", True):
                            yield cot_event
                    
                    yield {"type": "sql_analysis", "stage": "sql_generator", 
                           "content": {
                               "explanation": sql_result.get("explanation", ""),
                               "performance_notes": sql_result.get("performance_notes", ""),
                               "confidence": sql_result.get("confidence_score", 0)
                           }}
                else:
                    async for cot_event in add_cot_step("‚ö†Ô∏è SQL —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏", "warning", True):
                        yield cot_event
                    generated_sql_query = sql_result["sql"]
            else:
                generated_sql_query = sql_result
                
            analysis_context['sql_query'] = generated_sql_query
            
            async for cot_event in add_cot_step("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL –≥–æ—Ç–æ–≤ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é", "success", True):
                yield cot_event

        except Exception as e:
            async for cot_event in add_cot_step("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL, –∏—Å–ø–æ–ª—å–∑—É—é fallback", "error", True):
                yield cot_event
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –∏–∑ agents.py
            generated_sql_query = generate_fallback_sql({"data_scale": "medium"})
            analysis_context['sql_query'] = generated_sql_query
            print(f"[SQL_GENERATOR ERROR] {e}")

        yield {"type": "intermediary_result", "stage": "sql_generator", "name": "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π SQL", 
               "content": generated_sql_query, "language": "sql"}

        # === –≠–¢–ê–ü 6: –í–ê–õ–ò–î–ê–¶–ò–Ø –ò –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï ===
        async for cot_event in add_cot_step("üîç –í–∞–ª–∏–¥–∏—Ä—É—é SQL –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å"):
            yield cot_event

        current_stage = "–í–∞–ª–∏–¥–∞—Ü–∏—è SQL"
        validator_result = agent_sql_validator(generated_sql_query, plan_result)

        if validator_result.get("is_valid"):
            validated_sql = validator_result.get("corrected_sql") or generated_sql_query
            async for cot_event in add_cot_step("‚úÖ SQL –ø—Ä–æ—à—ë–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é", "success", True):
                yield cot_event
        else:
            async for cot_event in add_cot_step("üîß –ò—Å–ø—Ä–∞–≤–ª—è—é –æ—à–∏–±–∫–∏ –≤ SQL"):
                yield cot_event
            
            fixed_sql = agent_sql_fixer(generated_sql_query, validator_result.get("message", ""), plan_result)
            validated_sql = fixed_sql if fixed_sql and fixed_sql.strip() else generated_sql_query
            
            async for cot_event in add_cot_step("‚úÖ SQL –∏—Å–ø—Ä–∞–≤–ª–µ–Ω", "success", True):
                yield cot_event

        accumulated_data_for_rag["sql_query"] = validated_sql
        analysis_context['final_sql'] = validated_sql

        # === –≠–¢–ê–ü 7: –í–´–ü–û–õ–ù–ï–ù–ò–ï SQL ===
        async for cot_event in add_cot_step("‚ö° –í—ã–ø–æ–ª–Ω—è—é SQL-–∑–∞–ø—Ä–æ—Å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"):
            yield cot_event

        current_stage = "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL"
        try:
            sql_results_df = await execute_duckdb_query(duckdb_con, validated_sql)
            
            if sql_results_df is not None and not sql_results_df.empty:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º datetime –≤ —Å—Ç—Ä–æ–∫–∏
                for col in sql_results_df.columns:
                    if pd.api.types.is_datetime64_any_dtype(sql_results_df[col]):
                        sql_results_df[col] = sql_results_df[col].astype(str)
                
                records_count = len(sql_results_df)
                async for cot_event in add_cot_step(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {records_count:,} –∑–∞–ø–∏—Å–µ–π –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö", "success", True):
                    yield cot_event
                
                # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –î–û 100 –°–¢–†–û–ö
                display_df = sql_results_df.head(100)
                sql_results_json = display_df.to_dict(orient='records')
                
                analysis_context['data_retrieved'] = True
                analysis_context['records_count'] = records_count
                analysis_context['display_records'] = len(display_df)
                
                yield {"type": "sql_result", "stage": "sql_execution", "data": sql_results_json, 
                       "row_count": records_count, 
                       "message": f"SQL –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ. –ü–æ–∫–∞–∑–∞–Ω–æ {len(display_df)} –∏–∑ {records_count} –∑–∞–ø–∏—Å–µ–π."}
            else:
                async for cot_event in add_cot_step("‚ö†Ô∏è SQL –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã", "warning", True):
                    yield cot_event
                
                sql_results_json = []
                analysis_context['data_retrieved'] = False
                analysis_context['records_count'] = 0
                
                yield {"type": "sql_result", "stage": "sql_execution", "data": [], "row_count": 0, 
                       "message": "SQL –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç."}
                
        except Exception as e:
            async for cot_event in add_cot_step(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL: {str(e)[:50]}...", "error", True):
                yield cot_event
            yield {"type": "error", "stage": "sql_execution", "message": f"–û—à–∏–±–∫–∞ SQL: {str(e)}"}
            return

        # === –≠–¢–ê–ü 8: –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ê–ù–û–ú–ê–õ–ò–ô (–¢–û–ü-10) ===
        anomaly_summary = None
        if needs_anomaly_detection:
            async for cot_event in add_cot_step("üîç –ó–∞–ø—É—Å–∫–∞—é –¥–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π (—Ç–æ–ø-10 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)"):
                yield cot_event

            current_stage = "–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π"
            if sql_results_df is not None and not sql_results_df.empty:
                # –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ê–ù–ê–õ–ò–ó –ü–ï–†–í–´–ú–ò 1000 –°–¢–†–û–ö–ê–ú–ò
                analysis_df = sql_results_df.head(1000)
                anomaly_results = agent_anomaly_detector(analysis_df, processed_user_prompt)
                
                if anomaly_results.get('anomalies_found'):
                    anomaly_count = 0
                    if 'anomalies' in anomaly_results:
                        anomaly_count = sum(a.get('anomaly_count', 0) for a in anomaly_results['anomalies'])
                        async for cot_event in add_cot_step(f"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {anomaly_count} –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π!", "alert", True):
                            yield cot_event
                    else:
                        async for cot_event in add_cot_step("üö® –ù–∞–π–¥–µ–Ω—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–æ–º–∞–ª–∏–∏!", "alert", True):
                            yield cot_event
                else:
                    async for cot_event in add_cot_step("‚úÖ –ê–Ω–æ–º–∞–ª–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –¥–∞–Ω–Ω—ã–µ –≤ –Ω–æ—Ä–º–µ", "success", True):
                        yield cot_event

                analysis_context['anomaly_results'] = anomaly_results
                anomaly_summary = anomaly_results
                
                yield {"type": "intermediary_result", "stage": "anomaly_detection", 
                       "name": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–æ–º–∞–ª–∏–π (—Ç–æ–ø-10)", "content": anomaly_results}
            else:
                async for cot_event in add_cot_step("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–æ–º–∞–ª–∏–π", "warning", True):
                    yield cot_event

        # === –≠–¢–ê–ü 9: –°–ö–†–´–¢–ò–ï –¶–ï–ü–û–ß–ö–ò –†–ê–°–°–£–ñ–î–ï–ù–ò–ô ===
        async for cot_event in add_cot_step("üß† –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"):
            yield cot_event

        await asyncio.sleep(0.5)
        yield {"type": "cot_hide", "stage": "reasoning", "message": ""}
        await asyncio.sleep(0.7)

        # === –≠–¢–ê–ü 10: –ö–û–ú–ü–ê–ö–¢–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–¢–û–ì–û–í–û–ì–û –û–¢–í–ï–¢–ê ===
        current_stage = "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"
        yield {"type": "llm_analysis_start", "stage": "final_summary_generation", 
               "message": "–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞..."}

        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            llm_summary_result = generate_enhanced_final_response(
                sql_results_df, 
                processed_user_prompt, 
                anomaly_results=anomaly_summary,
                needs_anomaly_detection=needs_anomaly_detection,
                analysis_steps=len(cot_steps),
                analysis_context=analysis_context
            )
            
            accumulated_data_for_rag["final_answer"] = llm_summary_result
            
            print("[Stream] –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤.")
            yield {"type": "final_answer", "stage": "final_summary_generation", "answer": llm_summary_result, 
                   "rag_components": accumulated_data_for_rag, "message": "–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –≥–æ—Ç–æ–≤."}
            
        except Exception as e:
            print(f"[FINAL_ANALYSIS ERROR] –û—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            fallback_summary = f"**üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω**\n\n–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(sql_results_df) if sql_results_df is not None else 0} –∑–∞–ø–∏—Å–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É '{processed_user_prompt}'."
            
            accumulated_data_for_rag["final_answer"] = fallback_summary
            yield {"type": "final_answer", "stage": "final_summary_generation", "answer": fallback_summary, 
                   "rag_components": accumulated_data_for_rag, "message": "–†–µ–∑–µ—Ä–≤–Ω—ã–π –æ—Ç–≤–µ—Ç –≥–æ—Ç–æ–≤."}

    except Exception as e:
        error_message = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ '{current_stage}': {str(e)}"
        print(f"[EVENT_GENERATOR ERROR] {error_message}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –≤ —Ü–µ–ø–æ—á–∫—É —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
        try:
            async for cot_event in add_cot_step(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)[:50]}...", "error", True):
                yield cot_event
        except:
            pass
        
        yield {"type": "error", "stage": current_stage, "message": error_message}
    finally:
        print("[Stream] –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏.")
        yield {"type": "status", "stage": "done", "message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞."}

# ==============================================================================
# –≠–ù–î–ü–û–ò–ù–¢–´ (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
# ==============================================================================

@app.get("/process_query_stream")
async def process_query_stream(user_prompt: str, request: Request):
    """Endpoint –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å –ø–æ—Ç–æ–∫–æ–≤—ã–º –æ—Ç–≤–µ—Ç–æ–º"""
    duckdb_con = request.app.state.duckdb_con
    if not duckdb_con:
        return JSONResponse(status_code=500, content={"error": "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞."})
    
    if not user_prompt or not user_prompt.strip():
        return JSONResponse(status_code=400, content={"error": "user_prompt –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –∏–ª–∏ –ø—É—Å—Ç."})

    print(f"\n[API] –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: {user_prompt}")

    async def format_sse(data: dict) -> str:
        """Format data as SSE message"""
        return f"data: {json.dumps(data)}\n\n"

    async def event_stream():
        async for event in event_generator(user_prompt.strip(), duckdb_con):
            yield await format_sse(event)

    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "*",
            "Access-Control-Allow-Methods": "*"
        }
    )

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        if hasattr(app.state, 'duckdb_con') and app.state.duckdb_con:
            return {"status": "healthy", "service": "text2sql-enhanced", "database": "connected"}
        else:
            return {"status": "unhealthy", "service": "text2sql-enhanced", "database": "disconnected"}
    except Exception as e:
        return {"status": "unhealthy", "service": "text2sql-enhanced", "error": str(e)}

@app.get("/tables")
async def get_available_tables():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü"""
    return {
        "tables": [
            {"name": "population", "description": "–î–∞–Ω–Ω—ã–µ –æ —á–∏—Å–ª–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞—Å–µ–ª–µ–Ω–∏—è –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", "type": "demographic"},
            {"name": "salary", "description": "–î–∞–Ω–Ω—ã–µ –æ –∑–∞—Ä–∞–±–æ—Ç–Ω—ã—Ö –ø–ª–∞—Ç–∞—Ö –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º", "type": "economic"},
            {"name": "migration", "description": "–î–∞–Ω–Ω—ã–µ –æ –º–∏–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–∞—Ö", "type": "demographic"},
            {"name": "market_access", "description": "–ò–Ω–¥–µ–∫—Å—ã –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ä—ã–Ω–∫–æ–≤", "type": "economic"},
            {"name": "connections", "description": "–î–∞–Ω–Ω—ã–µ –æ —Å–≤—è–∑—è—Ö –º–µ–∂–¥—É —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è–º–∏", "type": "infrastructure"}
        ]
    }

# ==============================================================================
# EXCEPTION HANDLERS –ò STARTUP/SHUTDOWN
# ==============================================================================

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """–ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π"""
    print(f"[GLOBAL ERROR] –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞",
            "message": "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.",
            "type": "internal_server_error"
        }
    )

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    print("üöÄ –ó–∞–ø—É—Å–∫ Enhanced Text2SQL Multi-Agent System...")
    
    try:
        duckdb_connection = setup_duckdb()
        if duckdb_connection is not None:
            app.state.duckdb_con = duckdb_connection
            print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö DuckDB –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
            app.state.duckdb_con = None

        # Initialize RAG database
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π...")
        if not init_rag_db():
            print("[STARTUP ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG –±–∞–∑—É.")
        else:
            print("‚úÖ RAG –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        app.state.duckdb_con = None

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    print("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã Enhanced Text2SQL System...")
    
    try:
        if (hasattr(app.state, 'duckdb_con') and 
            app.state.duckdb_con is not None and
            hasattr(app.state.duckdb_con, 'close')):
            app.state.duckdb_con.close()
            print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–æ")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")

# ==============================================================================
# RAG SAVE ENDPOINT
# ==============================================================================

class RagSaveRequest(BaseModel):
    user_prompt: str
    formal_prompt: str
    plan: str
    sql_query: str
    final_answer: str

@app.post("/llm_query/confirm_and_save")
async def confirm_answer_and_save_to_rag(payload: RagSaveRequest):
    """Endpoint –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤ RAG –±–∞–∑—É"""
    print(f"[API /confirm_and_save] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ RAG: {payload.user_prompt[:50]}...")
    try:
        loop = asyncio.get_event_loop()
        success = await loop.run_in_executor(None, lambda: add_to_rag_db(
            user_prompt=payload.user_prompt,
            formal_prompt=payload.formal_prompt,
            plan=payload.plan,
            sql_query=payload.sql_query,
            final_answer=payload.final_answer
        ))

        if success:
            print(f"[API /confirm_and_save] –£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {payload.user_prompt[:50]}")
            return JSONResponse(content={"status": "success", "message": "–û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."}, status_code=200)
        else:
            print(f"[API /confirm_and_save] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {payload.user_prompt[:50]}")
            raise HTTPException(status_code=500, detail="–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.")
    except Exception as e:
        print(f"[API /confirm_and_save] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ RAG: {str(e)}")

# ==============================================================================
# –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê
# ==============================================================================

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ Enhanced Text2SQL Multi-Agent System...")
    
    if not os.path.isdir(STATIC_DIR):
        print(f"[CRITICAL ERROR] Static –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {STATIC_DIR}")
    elif not os.path.exists(INDEX_HTML_PATH):
        print(f"[CRITICAL ERROR] index.html –Ω–µ –Ω–∞–π–¥–µ–Ω: {INDEX_HTML_PATH}")
    
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=5002,
        reload=False,
        log_level="info",
        access_log=True
    )
